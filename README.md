# RAG_QA â€“ LLM-Only vs LLM + RAG JSON Question Answering

## ğŸ§© Project Overview
**RAG_QA** demonstrates how retrieval-augmented generation (RAG) improves the factual reliability of large language models (LLMs).  
It compares two pipelines:

| Mode | Description |
|------|--------------|
| **LLM-only** | The language model directly answers user questions using its internal knowledge â€” often producing hallucinations. |
| **LLM + RAG (JSON)** | The language model first interprets the userâ€™s intent, Python retrieves factual data from a structured JSON dataset, and the LLM then generates a grounded answer based on that context. |

Dataset: `data/cloud_storage.json`, containing real pricing and feature data for Google Drive, Dropbox, OneDrive, and Box.

---

## âš™ï¸ Architecture

```
User Question
      â”‚
      â–¼
[1] Semantic Parsing (LLM)
 â†’ {"Platform": "Dropbox", "Query": "cheapest"}
      â”‚
      â–¼
[2] JSON Retrieval (Python)
 â†’ find factual plans matching conditions
      â”‚
      â–¼
[3] Answer Generation (LLM)
 â†’ "The cheapest Dropbox plan is Plus, $15.99/month."
```

---

## ğŸ“‚ Project Structure
```
RAG_QA/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cloud_storage.json
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ api_client.py          # OpenAI client & .env loader
â”‚   â”œâ”€â”€ semantic_parser.py     # LLM-based semantic parsing
â”‚   â””â”€â”€ json_retriever.py      # Retrieve plans from JSON
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ llm_only.py            # Pure LLM answers
â”‚   â””â”€â”€ llm_with_json.py       # RAG pipeline (semantic + retrieval + generation)
â”‚
â”œâ”€â”€ main.py                    # CLI entry point
â””â”€â”€ .env                       # Contains OPENAI_API_KEY
```

---

## ğŸ› ï¸ Setup

### 1. Create environment
```bash
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate (Windows)
```

### 2. Install dependencies
```bash
pip install openai python-dotenv
```

### 3. Configure `.env`
```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
```

---

## ğŸš€ Run Demo
```bash
python main.py
```

Example interaction:
```
Enter your question: Which plan is cheapest on Dropbox?

[LLM-only answer]
Dropbox offers a free basic plan...

[LLM+JSON answer]
[STEP 1] semantic parse â†’ {'Platform': 'Dropbox', 'Query': 'cheapest'}
[STEP 2] retrieved cheapest plan â†’ {'Platform': 'Dropbox', 'PlanName': 'Plus', 'Price': 15.99, 'PlanType': 'Monthly'}
[STEP 3] generated answer:
The cheapest Dropbox plan is Plus, priced at $15.99 per month.
```

---

## ğŸ§  Key Components

### `semantic_parser.py`
Uses GPT-3.5-Turbo to interpret natural language questions and output structured JSON queries:
```json
{"Platform": "Dropbox", "Query": "cheapest"}
```
Later versions support richer filters such as budget ranges and feature preferences.

### `json_retriever.py`
Executes factual retrieval from `cloud_storage.json` based on parsed conditions  
(e.g., cheapest, budget range, supported features).

### `llm_with_json.py`
Combines semantic parsing + factual retrieval + answer generation â€” the essence of RAG.

---

## ğŸ“Š Expected Behavior
| Scenario | LLM-only | LLM + JSON (RAG) |
|-----------|-----------|------------------|
| â€œWhich plan is cheapest on Dropbox?â€ | May hallucinate a free 2 GB plan | Correctly answers â€œPlus $15.99/monthâ€ |
| â€œWhatâ€™s the largest plan on Google Drive?â€ | May guess outdated info | Retrieves 2 TB plan from JSON |
| â€œI want a monthly plan around $20 supporting video uploads.â€ | Not supported | (Extended parser) extracts budget + features and finds matching plans |

---

## ğŸ§© Extension Ideas
- Add support for compound filters (budget + features + storage size)  
- Evaluate accuracy vs. hallucination rate on custom question sets  
- Deploy as a cli or web demo (Streamlit / FastAPI)

---

## ğŸ“œ License
MIT License Â© 2025 RAG_QA Team
